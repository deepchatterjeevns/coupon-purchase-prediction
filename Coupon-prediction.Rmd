---
title: "Coupon Prediction"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Introduction and Business Case
This project aims to predict a coupon purchase if a user views a coupon. To achieve this, variables that affect users' purchase decisions will be determined. 
Data sets are obtained from Kaggle's "Coupon Purchase Prediction" challenge, in which the coupon purchases are to be predicted based on past coupons' viewing data released by Recruit Ponpare, a Japanese coupon site. 

Flow of report:
This report will first seek to understand the various data sets provided by Kaggle's "Coupon Purchase Prediction". Then the data will require cleaning, such as the removal of NAs and the reduction of data size to facilitate faster system time for running of data. With the cleaned data, exploration will be conducted to identify relationships between various variables and the purchase of coupons. Next, features for classification models will be engineered and these classification models will be used to model the coupon purchase prediction case. A comparison amongst the various models will be conducted at the end of the report to determine the most accurate and best fit classification model. Last but not least, recommendations to encourage and improve users' purchase of coupons will be suggested for Recruit Ponpare to use. 

```{r}
library(dplyr)
```

```{r}
dir <- './data/'
area_train <- read.csv(paste0(dir,"coupon_area_train_en.csv")) #translated to en
list_train <- read.csv(paste0(dir,"coupon_list_train_en.csv")) #translated to en
user_list <- read.csv(paste0(dir,"user_list_en.csv"), na.strings=c("", NA))
pref_locations <- read.csv(paste0(dir,"prefecture_locations_en.csv"))
visit <- read.csv(paste0(dir,"coupon_view_3months.csv"))

detail_train <- read.csv(paste0(dir,"coupon_detail_train_en.csv"))

# not using:
# colnames(detail_train$SMALL_AREA_NAME) change col name to residential small area
# list_test <- read.csv(paste0(dir,"coupon_list_test.csv"))
# visit_train <- read.csv(paste0(dir,"coupon_visit_train.csv")) # big file
# visit_train <- visit_train[visit_train$PURCHASE_FLG!=1,c("VIEW_COUPON_ID_hash","USER_ID_hash")]
```

## Understanding coupon area train data
each COUPON_ID_hash can have multiple rows. selecting one example of COUPON_ID_hash reveals that each coupon can be listed for multiple locations.
```{r}
sum(duplicated(area_train$COUPON_ID_hash))
head(area_train[duplicated(area_train$COUPON_ID_hash),])
area_train[area_train$COUPON_ID_hash == "7d1ce87a632bc4a57cfb4fc4a895cced",]

# one coupn can be listed in more than one prefecture
head(table(area_train$COUPON_ID_hash,area_train$PREF_NAME))
```

## Understanding coupon list train
This dataset contains characteristics of each coupon.
There are no duplicates. Each row is one coupon.
There is location information (ken, small area name, large area name) for each coupon in this data set. But each coupon can have multiple locations as seen in area_train. How is the location determined in list_train?
```{r}
head(list_train)
sum(duplicated(list_train$COUPON_ID_hash))

# looking at the same coupon ID as in area_train, the location in list_train is one of the many locations in area_train.
list_train[list_train$COUPON_ID_hash == "7d1ce87a632bc4a57cfb4fc4a895cced",]
# ken = Hyogo Prefecture

```

## Coupon Detail train
This data set contains purchase log of users.
A quick look at the data reveals that one user can purchase the same coupon of the same location at different times, each generating a row in this data set.
What happens when a user purchases the same coupon at two locations at the same time? does this generate two rows or one row?

```{r}
head(detail_train)
head(detail_train[duplicated(detail_train$USER_ID_hash),])

```

## test set is a different set of coupons from train

## are the test coupons in the view log?

## Understanding User list
Prefecture (not small area) is provided
```{r}
head(user_list)
str(user_list)
```

## Data cleaning/wrangling
Rename columns to differentiate user and coupon prefecture
```{r}
names(user_list)[names(user_list)=="en_pref"] <- "user_pref"
names(list_train)[names(list_train)=="en_ken"] <- "coupon_pref"
```

Selecting more relevant columns to reduce dataframe size
```{r}
# list_train <- subset(list_train, select=c(COUPON_ID_hash,en_capsule,en_genre,PRICE_RATE,CATALOG_PRICE,DISCOUNT_PRICE,VALIDPERIOD,en_small_area,coupon_pref))
# user_list <- subset(user_list,select = c(USER_ID_hash,AGE,SEX_ID,user_pref))
```

There are missing prefecture data in user_list. Why are there missing residential addresses? Have these users purchased something?
```{r}
cat(sum(is.na(user_list$user_pref)), "users with missing pref location\n")
# Checking if all purchased coupons have a user residential area name

cat("purchases without user residential area recorded:", sum(is.na(detail_train$SMALL_AREA_NAME)),"\n" )
# no NAs, every coupon purchase has a user residential area recorded

cat(sum(user_list[is.na(user_list$user_pref), "USER_ID_hash" ] %in% unique(detail_train[!is.na(detail_train$SMALL_AREA_NAME), "USER_ID_hash"])), "users without pref name in user_list but has small area residential name in detail_train\n")

# sum( unique(detail_train[!is.na(detail_train$SMALL_AREA_NAME), "USER_ID_hash"] %in% user_list[is.na(user_list$user_pref), "USER_ID_hash" ]))

```
Can we use SMALL_AREA_NAME to get prefecture name for the users without a residential prefecture recorded? SMALL_AREA_NAME is the "User redidential area name" according to Kaggle Data page, but a quick check revealed that the same user can be listed in multiple locations on the purchase log, yet have no registered address in the user list. How could that be?

```{r}
head(detail_train[,c("USER_ID_hash", "SMALL_AREA_NAME")], n=10)
```

Browsing some coupon pages revealed that coupons like restaurant discount tickets or physical products have to be delivered to an address.

```"Discount ticket" will be delivered to the designated address at the time of purchase by "Kuroneko DM flight"```

That explains multiple small areas associated with each user. Coupons could be delivered either to the user's or friend's/family's address. With this in mind, we can fill up missing prefectures in user_list using the most common prefecture the coupons are delivered to.

```{r}
# Get (small area name - prefecture name) association from list_train
small.area.pref <- unique(list_train[,c("en_small_area", "coupon_pref")])

# Merge with detail train to get prefecture for small area
detail_train <- merge(detail_train, small.area.pref, by.x = "en_SMALL_AREA_NAME", by.y = "en_small_area", all.x = TRUE)

# Get most frequent prefecture for each user from purchase log
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

mode.pref <- detail_train %>% 
  group_by(USER_ID_hash) %>%
  summarize(mode.pref = getmode(coupon_pref))

user_list <- merge(user_list, mode.pref, by = "USER_ID_hash", all.x = TRUE)

user_list$user_pref <- as.character(user_list$user_pref)
user_list$mode.pref <- as.character(user_list$mode.pref)
user_list$user_pref <- ifelse(is.na(user_list$user_pref), user_list$mode.pref, user_list$user_pref)
user_list$mode.pref <- NULL
```

# Preparing data for modeling
Rows from view log contain multiple of the same coupon-user pair, because each user can view multiple times then eventually purchase during another session, each recorded as one row.
Summarizing into unique coupon-user pairs, in that users who eventually bought will be classified as purchased.
```{r}
visit.info<- visit %>%
  group_by(VIEW_COUPON_ID_hash,USER_ID_hash)%>%
  summarise(purchase = max(PURCHASE_FLG), view_count = n())
```

merge visit, user characteristics, coupon characteristics
```{r}
dat <-merge(list_train,visit.info, by.x = "COUPON_ID_hash",by.y = "VIEW_COUPON_ID_hash")
dat <-merge(dat, user_list, by="USER_ID_hash")

drops <- c("large_area_name","ken_name","small_area_name","GENRE_NAME", "DISPFROM","DISPEND","VALIDFROM","VALIDEND","PREF_NAME","REG_DATE" ,"WITHDRAW_DATE", "CAPSULE_TEXT")
dat <- dat[, !(names(dat) %in% drops)]

```

```{r}
write.csv(dat, paste0(dir,"visit_user_coupon.csv"), row.names = F)
```

# Coupon data exploration (Cheryl)
```{r}
dat <- read.csv(paste0(dir,"visit_user_coupon.csv"))
```
List price
  (a) Relationship between discount rates and coupon genres
```{r}
ggplot(dat, aes(x=en_genre)) + geom_bar(aes(fill=discgroup), position="fill") + geom_point(aes(y=-0.05), size=0.75,alpha=0.3,position=position_jitter(h=0.01)) + ggtitle("Proportion of discount rates in each genre") + labs(x= "Genre", y="%") + theme(axis.text.x=element_text(angle=90,size=10,vjust = 0.5))
```
Lower discount rates are more commonly offered for these coupon genres: Food, hotel and Japanese hotel, and leisure. 
Food, hotel and Japanese hotel coupon genres are among the top 3 most visited coupons, which could explain why lower discount rates are given since demand for these coupons are high based on visit frequencies. 
High discount rates are more commonly offered for the other genres. Beauty genre offers 100% high discount rates. However, it can also be observed that the number of visits of coupon genres, beauty coupons had 0 visits. 


Does age (spending power) affect purchases by coupon genres?
```{r}
ggplot(dat) + geom_boxplot(aes(x=en_genre,y=AGE)) + ggtitle("Boxplot of users' age by genre") + labs(x="Genre", y="Age") + theme(axis.text.x=element_text(angle=90,size=10,vjust = 0.5))
```
For beauty coupons, it is evident that the age of users are relatively younger, which infers that these users may have lesser purchasing power than older users, thus higher discount rates are offered to encourage purchase of beauty coupons. 
Hotel and Japanese hotel, and leisure coupons have relatively higher age groups, albeit slightly, which is reasonable given that these coupon genres have lower discount rates. Food coupons do not seem to have relatively higher age groups, this could be because food coupons are more generic and applicable to all age groups.  


Most visited coupons #DELETE AFTER SHOWING TEAM
```{r}
library(ggplot2)

#delll
ggplot(dat) + geom_bar(aes(x=most_vist), fill="orange") + coord_flip() + theme(axis.text.y=element_text(size = rel(0.8)))

#Top 3 most visited coupon genres in descending order: Delivery service, food, hotel and Japanese hotel. 
#Top 2 most visited coupons genre == Top 2 most purchased coupons genre

#only purchased coupons
ggplot(dat[dat$purchase==1,]) + geom_bar(aes(x=most_vist), fill="orange") + coord_flip() + theme(axis.text.y=element_text(size = rel(0.8)))
```

  (b) Relationship between list price and discount rates (PRICE_RATE is no longer available in nic's csv)
```{r}
ggplot(data=dat, aes(x=CATALOG_PRICE,y=PRICE_RATE)) + geom_point() + stat_smooth(method="lm") + labs(x = "List price", y="Discount rate") + ggtitle("Discount rate v List price") + ylim(50,100) 
```
Based on the scatterplot, there does not seem to be an obvious correlation between the list price and discount rates, which means that discount rates are not given based on the list prices of coupons. 

  (c) Relationship of list price against periods
List price v Display period
```{r}
ggplot(data=dat, aes(x=DISPPERIOD,y=CATALOG_PRICE,color=en_genre)) + geom_point() + xlim(0,15) + labs(x="Display Period", y="List Price") + ggtitle("List price against Display period")
```
Display period of coupons do not seem to have an effect on list price. A small effect is observed only when display period is for 1 day, then list price is substantially lower than when display period is for 2 days, as shown by the clustering of list prices to the lower values when display period==1. 

List price v Valid period
```{r}
ggplot(data=dat2, aes(x=VALIDPERIOD,y=CATALOG_PRICE,color=en_genre)) + geom_point() + xlim(0,15) + ylim(0, 12500) + labs(x="Valid Period", y="List Price") + ggtitle("List price against Valid period")
```
No correlation is observed

List price v Total display and valid period
```{r}
dat$total.period <- dat$DISPPERIOD + dat$VALIDPERIOD

ggplot(data=dat, aes(x=total.period,y=CATALOG_PRICE,color=en_genre)) + geom_point() + xlim(0,15) + ylim(0, 12500) + labs(x="Display Period + Valid Period", y="List Price") + ggtitle("List price against Total period")
```
List price do not seem to be strongly influenced by display period nor valid period.

Purchased coupons
  (a) Views and purchases in each genre
```{r}
ggplot(dat, aes(x=en_genre)) + geom_bar(aes(fill=purchase)) + geom_point(aes(y=-0.05), size=0.75,alpha=0.3,position=position_jitter(h=0.01)) + ggtitle("Number of coupons viewed and purchased in each genre") + labs(x= "Genre", y="Number") + theme(axis.text.x=element_text(angle=90,size=10,vjust = 0.5))
```
Proportion of purchased coupons are low as compared to visits to a coupon without a purchase. 

Number of purchased coupons by genre
```{r}
ggplot(dat[dat$purchase==1,], aes(x=en_genre)) + geom_bar(aes(fill=purchase)) + geom_point(aes(y=-0.05), size=0.75,alpha=0.3,position=position_jitter(h=0.01)) + ggtitle("Number of purchases in each genre") + labs(x= "Genre", y="Number") + theme(axis.text.x=element_text(angle=90,size=10,vjust = 0.5))
```
Top 3 purchased coupons: Delivery service, food, other coupon
This is reasonable given that delivery service and food coupons are amongst the top 3 visited coupon genres as well.


  (b) Relationship of Display and Valid preiod against purchased coupons. 

Purchase flag v Display period
```{r}
ggplot(dat[dat$purchase==1,], aes(x=DISPPERIOD)) + geom_bar(aes()) + geom_point(aes(y=-0.05), size=0.75,alpha=0.3,position=position_jitter(h=0.01)) + ggtitle("Purchases by Display Periods") + labs(x= "Display period", y="Number") + theme(axis.text.x=element_text(angle=90,size=10,vjust = 0.5))
```
Highest number of purchases is observed when display period is at 4 days. A normal distribution is observed.?

Purchase flag v Valid period
```{r}
ggplot(dat[dat$purchase==1,], aes(x=VALIDPERIOD)) + geom_bar(aes()) + geom_point(aes(y=-0.05), size=0.75,alpha=0.3,position=position_jitter(h=0.01)) + ylim(0,500) + ggtitle("Purchases by Valid Periods") + labs(x= "Valid Period", y="Number") + theme(axis.text.x=element_text(angle=90,size=10,vjust = 0.5))
```
No observable pattern

Purchase flag v Total display and valid period
```{r}
ggplot(dat[dat$purchase==1,], aes(x=total.period)) + geom_bar(aes()) + geom_point(aes(y=-0.05), size=0.75,alpha=0.3,position=position_jitter(h=0.01)) + ylim(0,500) + ggtitle("Purchases by Total Period") + labs(x= "Display period + Valid period", y="Number") + theme(axis.text.x=element_text(angle=90,size=10,vjust = 0.5))
```
No observable pattern

A slight pattern can be observed with a higher likelihood of a purchase made when display period of a coupon is at 4 days.


# User exploration (des)

Age (Using nicholas's Age.Group code to divide)
```{r}
ggplot(user_list)+geom_density(aes(x=AGE))
ggplot(dat,aes(x=en_capsule,fill=Age.Group)) + geom_bar() + facet_wrap(~purchase) + coord_flip()
```
Overall, customers are mostly clustered between the 30-50 age group, but in terms of level of behaviour on the site, those in the 40-60 age range are more active. Popular genres which users view across all age groups are similiar - Delivery Service, Food, Hotels & Japanese Hotels in that order. However, if we look at purchasing behaviour, viewing coupons in the hotels genres do not translate to as many purchases, as "Other" genre coupons have better sales following Delivery Service and Food, although they are not viewed relatively as much. This suggests that users possibly take a longer time to make a purchase in the hotels genres, viewing multiple coupons before deciding. 

Gender
```{r}
ggplot(dat,aes(x=en_capsule,fill=SEX_ID)) + geom_bar() + facet_wrap(~purchase) + coord_flip()
```
Unsurprisingly, one's gender does influence the genre of coupons viewed, as seen in the graph, Female users view Hair Salon, Nail & Eye Salon, Spa & Relaxation genre coupons more often than their male counterparts who's views and purchases in these genre is basically non-existent. 

View/purchase activity v price (using cheryl's code which creates discgroup)
```{r}
ggplot(dat,aes(x=discgroup)) + geom_bar() + facet_wrap(~purchase) + coord_flip()
```
Having split the set of coupons into two almost equal groups of "LOW" and "HIGH" based on their discount rates, we then compared this to the level of user viewing and purchasing activity.  

Very intuitively, "HIGH" discount rate coupons were purchased more often, and this is despite the lower frequency of views. The level of discount offered is hence a compelling factor in the conversion of a "view" to a "purchase".


Purchase activity by user prefecture vs no. of coupons usable there
```{r}
ggplot(dat[!is.na(dat$en_pref) & dat$purchase ==1,],aes(x=en_pref)) + geom_bar()  + coord_flip()
ggplot(area_train[!is.na(area_train$en_pref)], aes(x=en_pref)) + geom_bar() + coord_flip()
ggplot(user_list[!is.na(user_list$en_pref)], aes(x=en_pref)) + geom_bar() + coord_flip()
dat$purchase_oop <- ifelse(dat$purchase == 1 & data$match_pref == 0,"Outside of Prefecture","Within Prefecture")
ggplot(dat[dat$purchase == 1,], aes(x=purchase_oop)) + geom_bar() + coord_flip()
```
Following intuition, the frequency of purchases by users in Tokyo, Osaka & Kanagawa prefectures is  much greater than the others and this correlates with both the number of coupons available for use in these locations as well as the number of users in each location. However, notably almost 1/3 of coupon purchased are actually only usable outside of their prefecture. 


# Feature Engineering
```{r}
dat <- read.csv(paste0(dir,"visit_user_coupon.csv"))
```

distance between user and coupon default prefecture
```{r}
library(geosphere)

prefs <- pref_locations[,c("LATITUDE", "LONGITUDE", "en_PREF_NAME")]

names(prefs) <- c("coupon_LATITUDE", "coupon_LONGITUDE", "en_PREF_NAME")
dat <- merge(dat, prefs, by.x = "coupon_pref", by.y = "en_PREF_NAME", all.x = TRUE)

names(prefs) <- c("user_LATITUDE", "user_LONGITUDE", "en_PREF_NAME")
dat <- merge(dat, prefs, by.x = "user_pref", by.y = "en_PREF_NAME", all.x = TRUE)

dat$user.coupon.dist <- sqrt(I(dat$coupon_LATITUDE - dat$user_LATITUDE)^2 + I(dat$coupon_LONGITUDE - dat$user_LONGITUDE)^2)

drops_latlon <- c("coupon_LATITUDE","user_LATITUDE","coupon_LONGITUDE","user_LONGITUDE")
dat <- dat[, !(names(dat) %in% drops_latlon)]
```

most frequently visited genre
```{r}
mode.genre <- dat %>% 
  group_by(USER_ID_hash) %>%
  summarize(mode.visit.genre = getmode(en_genre))

dat <- merge(dat, mode.genre,by = "USER_ID_hash",all.x = TRUE)
```

distance between user and coupon nearest branch prefecture
```{r}
coupon_branches <- unique(area_train[,c("COUPON_ID_hash", "en_pref")])
#WIP
```

most frequent gender viewing coupons
```{r}
mode.gender <- dat %>% 
  group_by(COUPON_ID_hash) %>%
  summarize(mode.visit.gender = getmode(SEX_ID))

dat <- merge(dat, mode.gender,by = "COUPON_ID_hash",all.x = TRUE)
```

most frequent age group viewing coupons
```{r}
dat$age_group<-cut(dat$AGE, 
                          breaks = c(15, 22, 30, 40, 50, 60, 85), 
                          labels = c("15 to 21", "22 to 29", "30 to 39", "40 to 49", "50 to 59", "60 to 85"), 
                          right = FALSE)
mode.agegroup <- dat %>% 
  group_by(COUPON_ID_hash) %>%
  summarize(mode.visit.agegroup = getmode(age_group))
dat <- merge(dat, mode.agegroup, by = "COUPON_ID_hash",all.x = TRUE)
```

Get weekend, weekday flags. NA is converted to 1 because if not given, it is usable every day.
```{r}
dat$USABLE_DATE_Weekday<-ifelse(dat$USABLE_DATE_FRI!=0|dat$USABLE_DATE_THU!=0|dat$USABLE_DATE_WED!=0|dat$USABLE_DATE_TUE!=0|dat$USABLE_DATE_MON!=0,1,0)
dat$USABLE_DATE_Weekday[is.na(dat$USABLE_DATE_Weekday)] <- 1
dat$USABLE_DATE_Weekend<-ifelse(dat$USABLE_DATE_SAT!=0|dat$USABLE_DATE_SUN!=0,1,0)
dat$USABLE_DATE_Weekend[is.na(dat$USABLE_DATE_Weekend)] <- 1
dat$USABLE_DATE_HOLIDAY<-ifelse(dat$USABLE_DATE_HOLIDAY!=0,1,0)
dat$USABLE_DATE_HOLIDAY[is.na(dat$USABLE_DATE_HOLIDAY)] <- 1
dat$USABLE_DATE_BEFORE_HOLIDAY<-ifelse(dat$USABLE_DATE_BEFORE_HOLIDAY!=0,1,0)
dat$USABLE_DATE_BEFORE_HOLIDAY[is.na(dat$USABLE_DATE_BEFORE_HOLIDAY)] <- 1

drops_dayofweek <- c("USABLE_DATE_MON","USABLE_DATE_TUE","USABLE_DATE_WED","USABLE_DATE_THU", "USABLE_DATE_FRI","USABLE_DATE_SAT","USABLE_DATE_SUN")
dat <- dat[, !(names(dat) %in% drops_dayofweek)]

dat$USABLE_DATE_HOLIDAY<-as.factor(dat$USABLE_DATE_HOLIDAY)
dat$USABLE_DATE_BEFORE_HOLIDAY<-as.factor(dat$USABLE_DATE_BEFORE_HOLIDAY)
dat$USABLE_DATE_Weekday<-as.factor(dat$USABLE_DATE_Weekday)
dat$USABLE_DATE_Weekend<-as.factor(dat$USABLE_DATE_Weekend)
```

```{r}
library(ggplot2)
table(dat$PRICE_RATE)
ggplot(dat) + geom_bar(aes(x=PRICE_RATE), fill="blue")
dat$discgroup <- ifelse(dat$PRICE_RATE <= 55, "LOW", "HIGH")
dat$discgroup <- as.factor(dat$discgroup)
dat $PRICE_RATE <- NULL
```

drop user and coupon IDs & set as factor
```{r}
dat$USER_ID_hash <- NULL
dat$COUPON_ID_hash <- NULL

dat$user_pref<-as.factor(dat$user_pref)
dat$purchase<-as.factor(dat$purchase)
```

removal of NAs
```{r}
dat<-dat %>% 
  group_by(en_genre) %>% 
  mutate(VALIDPERIOD= replace(VALIDPERIOD, is.na(VALIDPERIOD), mean(VALIDPERIOD, na.rm=TRUE)))

dat$user.coupon.dist<-as.numeric(dat$user.coupon.dist)

dat<-dat %>% 
  group_by(age_group) %>% 
  mutate(user.coupon.dist= replace(user.coupon.dist, is.na(user.coupon.dist), mean(user.coupon.dist, na.rm=TRUE)))

dat$user_pref<-as.character(dat$user_pref)
dat$user_pref[is.na(dat$user_pref)]<-"Unknown"
dat$user_pref<-as.factor(dat$user_pref)
```

```{r}
write.csv(dat, paste0(dir,"visit_user_coupon_features.csv"), row.names = F)
```

## Split into test and train dataset

```{r}
dat <- read.csv(paste0(dir,"visit_user_coupon_features.csv"))
```

```{r}
set.seed(4217)
sample <- sample(sample(c(TRUE,FALSE),nrow(dat),prob = c(0.70,0.30),replace = TRUE))
test <- dat[!sample,]
train <- dat[sample,]

write.csv(train, paste0(dir,"visit_train.csv"), row.names = F)
write.csv(test, paste0(dir,"visit_test.csv"), row.names = F)
```

```{r}
library(caret)
ctrl <- trainControl(method = "repeatedcv", number = 10,savePredictions = TRUE)
log_fit <- train(match ~ .,  data=trainData, method="LogitBoost", family="binomial",trControl = ctrl)
predictors(log_fit)
```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

