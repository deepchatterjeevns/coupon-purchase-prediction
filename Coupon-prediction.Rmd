---
title: "Coupon Prediction"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(dplyr)
```

```{r}
dir <- './data/'
area_train <- read.csv(paste0(dir,"coupon_area_train_en.csv")) #translated to en
list_train <- read.csv(paste0(dir,"coupon_list_train_en.csv")) #translated to en
user_list <- read.csv(paste0(dir,"user_list_en.csv"), na.strings=c("", NA))
pref_locations <- read.csv(paste0(dir,"prefecture_locations_en.csv"))
visit <- read.csv(paste0(dir,"coupon_view_1month.csv"))

detail_train <- read.csv(paste0(dir,"coupon_detail_train_en.csv"))

# not using:
# colnames(detail_train$SMALL_AREA_NAME) change col name to residential small area
# list_test <- read.csv(paste0(dir,"coupon_list_test.csv"))
# visit_train <- read.csv(paste0(dir,"coupon_visit_train.csv")) # big file
# visit_train <- visit_train[visit_train$PURCHASE_FLG!=1,c("VIEW_COUPON_ID_hash","USER_ID_hash")]
```

## Understanding coupon area train data
each COUPON_ID_hash can have multiple rows. selecting one example of COUPON_ID_hash reveals that each coupon can be listed for multiple locations.
```{r}
sum(duplicated(area_train$COUPON_ID_hash))
head(area_train[duplicated(area_train$COUPON_ID_hash),])
area_train[area_train$COUPON_ID_hash == "7d1ce87a632bc4a57cfb4fc4a895cced",]

# one coupn can be listed in more than one prefecture
head(table(area_train$COUPON_ID_hash,area_train$PREF_NAME))
```

## Understanding coupon list train
This dataset contains characteristics of each coupon.
There are no duplicates. Each row is one coupon.
There is location information (ken, small area name, large area name) for each coupon in this data set. But each coupon can have multiple locations as seen in area_train. How is the location determined in list_train?
```{r}
head(list_train)
sum(duplicated(list_train$COUPON_ID_hash))

# looking at the same coupon ID as in area_train, the location in list_train is one of the many locations in area_train.
list_train[list_train$COUPON_ID_hash == "7d1ce87a632bc4a57cfb4fc4a895cced",]
# ken = Hyogo Prefecture

```

## Coupon Detail train
This data set contains purchase log of users.
A quick look at the data reveals that one user can purchase the same coupon of the same location at different times, each generating a row in this data set.
What happens when a user purchases the same coupon at two locations at the same time? does this generate two rows or one row?

```{r}
head(detail_train)
head(detail_train[duplicated(detail_train$USER_ID_hash),])

```

## test set is a different set of coupons from train

## are the test coupons in the view log?

## Understanding User list
Prefecture (not small area) is provided
```{r}
head(user_list)
str(user_list)
```

## Data cleaning/wrangling
Rename columns to differentiate user and coupon prefecture
```{r}
names(user_list)[names(user_list)=="en_pref"] <- "user_pref"
names(list_train)[names(list_train)=="en_ken"] <- "coupon_pref"
```

There are missing prefecture data in user_list. Why are there missing residential addresses? Have these users purchased something?
```{r}
cat(sum(is.na(user_list$user_pref)), "users with missing pref location\n")
# Checking if all purchased coupons have a user residential area name

cat("purchases without user residential area recorded:", sum(is.na(detail_train$SMALL_AREA_NAME)),"\n" )
# no NAs, every coupon purchase has a user residential area recorded

cat(sum(user_list[is.na(user_list$user_pref), "USER_ID_hash" ] %in% unique(detail_train[!is.na(detail_train$SMALL_AREA_NAME), "USER_ID_hash"])), "users without pref name in user_list but has small area residential name in detail_train\n")

# sum( unique(detail_train[!is.na(detail_train$SMALL_AREA_NAME), "USER_ID_hash"] %in% user_list[is.na(user_list$user_pref), "USER_ID_hash" ]))

```

Can we use SMALL_AREA_NAME to get prefecture name for the users without a residential prefecture recorded? SMALL_AREA_NAME is the "User redidential area name" according to Kaggle Data page, but a quick check revealed that the same user can be listed in multiple locations on the purchase log, yet have no registered address in the user list. How could that be?

```{r}
head(detail_train[,c("USER_ID_hash", "SMALL_AREA_NAME")], n=10)
```

Browsing some coupon pages revealed that coupons like restaurant discount tickets or physical products have to be delivered to an address.

```"Discount ticket" will be delivered to the designated address at the time of purchase by "Kuroneko DM flight"```

That explains multiple small areas associated with each user. Coupons could be delivered either to the user's or friend's/family's address. With this in mind, we can fill up missing prefectures in user_list using the most common prefecture the coupons are delivered to.

```{r}
# Get (small area name - prefecture name) association from list_train
small.area.pref <- unique(list_train[,c("en_small_area", "coupon_pref")])

# Merge with detail train to get prefecture for small area
detail_train <- merge(detail_train, small.area.pref, by.x = "en_SMALL_AREA_NAME", by.y = "en_small_area", all.x = TRUE)

# Get most frequent prefecture for each user from purchase log
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

mode.pref <- detail_train %>% 
  group_by(USER_ID_hash) %>%
  summarize(mode.pref = getmode(coupon_pref))

user_list <- merge(user_list, mode.pref, by = "USER_ID_hash", all.x = TRUE)

user_list$user_pref <- as.character(user_list$user_pref)
user_list$mode.pref <- as.character(user_list$mode.pref)
user_list$user_pref <- ifelse(is.na(user_list$user_pref), user_list$mode.pref, user_list$user_pref)
user_list$mode.pref <- NULL
```

# Preparing data for modeling
Rows from view log contain multiple of the same coupon-user pair, because each user can view multiple times then eventually purchase during another session, each recorded as one row.
Summarizing into unique coupon-user pairs, in that users who eventually bought will be classified as purchased.
```{r}
visit.info<- visit %>%
  group_by(VIEW_COUPON_ID_hash,USER_ID_hash)%>%
  summarise(purchase = max(PURCHASE_FLG), view_count = n())
```

merge visit.info, user characteristics, coupon characteristics
Drop irrelevant columns to reduce dataframe size
```{r}
dat <-merge(list_train,visit.info, by.x = "COUPON_ID_hash",by.y = "VIEW_COUPON_ID_hash")
dat <-merge(dat, user_list, by="USER_ID_hash")

drops <- c("large_area_name","ken_name","small_area_name","GENRE_NAME", "DISPFROM","DISPEND","VALIDFROM","VALIDEND","PREF_NAME","REG_DATE" ,"WITHDRAW_DATE", "CAPSULE_TEXT", "en_large_area", "en_small_area")
dat <- dat[, !(names(dat) %in% drops)]

```

```{r}
write.csv(dat, paste0(dir,"visit_user_coupon.csv"), row.names = F)
```

# Feature Engineering
```{r}
dat <- read.csv(paste0(dir,"visit_user_coupon.csv"))
```

distance between user and coupon default prefecture
```{r}

prefs <- pref_locations[,c("LATITUDE", "LONGITUDE", "en_PREF_NAME")]

names(prefs) <- c("coupon_LATITUDE", "coupon_LONGITUDE", "en_PREF_NAME")
dat <- merge(dat, prefs, by.x = "coupon_pref", by.y = "en_PREF_NAME", all.x = TRUE)

names(prefs) <- c("user_LATITUDE", "user_LONGITUDE", "en_PREF_NAME")
dat <- merge(dat, prefs, by.x = "user_pref", by.y = "en_PREF_NAME", all.x = TRUE)

dat$user.coupon.dist <- sqrt(I(dat$coupon_LATITUDE - dat$user_LATITUDE)^2 + I(dat$coupon_LONGITUDE - dat$user_LONGITUDE)^2)

drops_latlon <- c("coupon_LATITUDE","user_LATITUDE","coupon_LONGITUDE","user_LONGITUDE", "coupon_pref")
dat <- dat[, !(names(dat) %in% drops_latlon)]

```

most frequently visited genre
```{r}
mode.genre <- dat %>% 
  group_by(USER_ID_hash) %>%
  summarize(mode.visit.genre = getmode(en_genre))

dat <- merge(dat, mode.genre,by = "USER_ID_hash",all.x = TRUE)

##Genre Match
dat$en_genre<-as.character(dat$en_genre)
dat$mode.visit.genre<-as.character(dat$mode.visit.genre)
dat$same.genre <- dat$en_genre==dat$mode.visit.genre

dat$en_capsule <- NULL
dat$mode.visit.genre <- NULL
dat$en_genre<-factor(dat$en_genre)
```

distance between user and coupon nearest branch prefecture
```{r}
#WIP
coupon_branches <- unique(area_train[,c("COUPON_ID_hash", "en_pref")])
```

most frequent gender viewing coupons
```{r}
mode.gender <- dat %>% 
  group_by(COUPON_ID_hash) %>%
  summarize(mode.visit.gender = getmode(SEX_ID))

dat <- merge(dat, mode.gender,by = "COUPON_ID_hash",all.x = TRUE)

## If Match
dat$same.gender <- dat$SEX_ID == dat$mode.visit.gender

dat$mode.visit.gender<-NULL
```

most frequent age group viewing coupons
```{r}
dat$age_group<-cut(dat$AGE, 
                          breaks = c(15, 22, 30, 40, 50, 60, 85), 
                          labels = c("15 to 21", "22 to 29", "30 to 39", "40 to 49", "50 to 59", "60 to 85"), 
                          right = FALSE)
mode.agegroup <- dat %>% 
  group_by(COUPON_ID_hash) %>%
  summarize(mode.visit.agegroup = getmode(age_group))
dat <- merge(dat, mode.agegroup, by = "COUPON_ID_hash",all.x = TRUE)

## If Match
dat$same.age.group <- dat$age_group == dat$mode.visit.agegroup

dat$mode.visit.agegroup<-NULL
```

Get weekend, weekday flags. NA is converted to 1 because if not given, it is usable every day.
```{r}
dat$USABLE_DATE_Weekday<-ifelse(dat$USABLE_DATE_FRI!=0|dat$USABLE_DATE_THU!=0|dat$USABLE_DATE_WED!=0|dat$USABLE_DATE_TUE!=0|dat$USABLE_DATE_MON!=0,1,0)
dat$USABLE_DATE_Weekday[is.na(dat$USABLE_DATE_Weekday)] <- 1
dat$USABLE_DATE_Weekend<-ifelse(dat$USABLE_DATE_SAT!=0|dat$USABLE_DATE_SUN!=0,1,0)
dat$USABLE_DATE_Weekend[is.na(dat$USABLE_DATE_Weekend)] <- 1
dat$USABLE_DATE_HOLIDAY<-ifelse(dat$USABLE_DATE_HOLIDAY!=0,1,0)
dat$USABLE_DATE_HOLIDAY[is.na(dat$USABLE_DATE_HOLIDAY)] <- 1
dat$USABLE_DATE_BEFORE_HOLIDAY<-ifelse(dat$USABLE_DATE_BEFORE_HOLIDAY!=0,1,0)
dat$USABLE_DATE_BEFORE_HOLIDAY[is.na(dat$USABLE_DATE_BEFORE_HOLIDAY)] <- 1

drops_dayofweek <- c("USABLE_DATE_MON","USABLE_DATE_TUE","USABLE_DATE_WED","USABLE_DATE_THU", "USABLE_DATE_FRI","USABLE_DATE_SAT","USABLE_DATE_SUN")
dat <- dat[, !(names(dat) %in% drops_dayofweek)]

dat$USABLE_DATE_HOLIDAY<-as.factor(dat$USABLE_DATE_HOLIDAY)
dat$USABLE_DATE_BEFORE_HOLIDAY<-as.factor(dat$USABLE_DATE_BEFORE_HOLIDAY)
dat$USABLE_DATE_Weekday<-as.factor(dat$USABLE_DATE_Weekday)
dat$USABLE_DATE_Weekend<-as.factor(dat$USABLE_DATE_Weekend)
```

```{r}
dat$discgroup <- ifelse(dat$PRICE_RATE <= 55, "LOW", "HIGH")
dat$discgroup <- as.factor(dat$discgroup)
dat$PRICE_RATE <- NULL
```

Remove NAs
```{r}
dat<-dat %>% 
  group_by(en_genre) %>% 
  mutate(VALIDPERIOD = replace(VALIDPERIOD, is.na(VALIDPERIOD), mean(VALIDPERIOD, na.rm=TRUE)))

dat$user.coupon.dist <- as.numeric(dat$user.coupon.dist)
dat<-dat %>% 
  group_by(age_group) %>% 
  mutate(user.coupon.dist= replace(user.coupon.dist, is.na(user.coupon.dist), mean(user.coupon.dist, na.rm=TRUE)))

dat$user_pref <- as.character(dat$user_pref)
dat$user_pref[is.na(dat$user_pref)] <- "Unknown"
dat$user_pref <- as.factor(dat$user_pref)
```

drop user and coupon IDs & set as factor
```{r}
dat <-subset(dat,select = -c(USER_ID_hash, COUPON_ID_hash))
```

# insert code for more cleaning

```{r}
write.csv(dat, paste0(dir,"visit_user_coupon_features.csv"), row.names = F)
```

If reading new file:
```{r}
dat <- read.csv(paste0(dir,"visit_user_coupon_features.csv"))
dat$USABLE_DATE_HOLIDAY<-as.factor(dat$USABLE_DATE_HOLIDAY)
dat$USABLE_DATE_BEFORE_HOLIDAY<-as.factor(dat$USABLE_DATE_BEFORE_HOLIDAY)
dat$USABLE_DATE_Weekday<-as.factor(dat$USABLE_DATE_Weekday)
dat$USABLE_DATE_Weekend<-as.factor(dat$USABLE_DATE_Weekend)
```

## Split into test and train dataset
```{r}
dat$purchase<-as.factor(dat$purchase)

# feature.names <- names(dat)
# for (f in feature.names) {
#   if (class(dat[[f]])=="factor") {
#     levels <- unique(c(dat[[f]]))
#     dat[[f]] <- factor(dat[[f]],
#                    labels=make.names(levels))
#   }
# }
```

```{r}
# dat<-dat[ sample( -which( dat$purchase == 0 ) , 370000 ) , ]
```

```{r}
set.seed(123)
sample <- sample(sample(c(TRUE,FALSE),nrow(dat),prob = c(0.70,0.30),replace = TRUE))
test <- dat[!sample,]
train <- dat[sample,]

write.csv(train, paste0(dir,"visit_train.csv"), row.names = F)
write.csv(test, paste0(dir,"visit_test.csv"), row.names = F)
```


```{r}
library(caret)
library(caTools)
auc_pr<- function(obs, pred) {
  xx.df <- prediction(pred, obs)
  perf  <- performance(xx.df, "prec", "rec")
  xy    <- data.frame(recall=perf@x.values[[1]], precision=perf@y.values[[1]])
  
  # take out division by 0 for lowest threshold
  xy <- subset(xy, !is.nan(xy$precision))
  
  # Designate recall = 0 as precision = x...arbitrary
  xy <- rbind(c(0, 0), xy)
  #xy <- xy[!(rowSums(xy)==0), ]
  
  res   <- trapz(xy$recall, xy$precision)
  res
}
```

## Logistic Regression
```{r}
ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE, classProbs = TRUE)
log_fit <- train(match ~ .,  data=trainData, method="LogitBoost", family="binomial",trControl = ctrl)
predictors(log_fit)
```

## Decision Tree
```{r}
ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)
set.seed(4217)
dtree <- train(purchase ~ ., data = train, method = "rpart", trControl = ctrl, parms=list(split='information'))

library(rattle)
fancyRpartPlot(dtree$finalModel)

rpartProbs <- predict(dtree, train, type = "prob")
summary(rpartProbs)

auc_pr(train$purchase, rpartProbs$`1`)

library(ROCR)
pr <- prediction(rpartProbs$`1`, train$purchase)
X<-performance(pr,measure= "prec", x.measure= "rec")
performance(pr,measure= "prbe")
plot(X)
```

```{r}
rpartPred <- predict(dtree, train)
confusionMatrix(rpartPred, train$purchase)
```

Try with rpart package
```{r}
library(rpart)

dtree.rpart <- rpart(purchase ~ ., data=train, method="class", parms=list(split="information"))

library(rpart.plot)
prp(dtree.rpart, type=2, extra=104, fallen.leaves = TRUE, main="Decision Tree")
```



```{r}

```

```{r}

```

parallel
```{r}
library(doMC)
```

